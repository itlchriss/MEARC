import subprocess
import sys
import yaml
import os
from optparse import OptionParser
from typing import Dict, Tuple
from yaml.loader import SafeLoader
from typing import List, Tuple

################################################
# VERY IMPORTANT!!!!!
#  Using depccg we need to copy semantic_templates_en_event_flat.yaml from ccg2lambda to depccg model directory
################################################

sys.path.append('./src/python')
# from pipeline_depccg import call_depccg_pipeline

_configs = {'ROOT': 'ROOT', 'NLP': 'NLP', 'STD_SI': 'STD_SI', 'PYCMD': 'PYCMD', 'TMP': 'TMP'}
nlp_path = None
si_path = None
frontends = ['ccg2lambda', 'depccg']

debug = True
info = False
frontend = 'ccg2lambda'

optparser = OptionParser()
optparser.add_option("-d", "--debug", dest="debuglevel", help="debug level. 1 = INFO, 2 = DEBUG")
optparser.add_option("-f", "--file", dest="prog_path", help="path of the program file")
optparser.add_option("-q", "--query", dest="query", help="path of the query file")
optparser.add_option("-p", "--profquery", dest="prof_query", help="path of the professional query file")
optparser.add_option("-c", "--config", dest="config_path", help="path of the config file")
optparser.add_option("-e", "--frontend", dest="frontend", help="ccg2lambda or depccg")


class dot_access_dict(dict):
    __getattr__ = dict.get
    __setattr__ = dict.__setitem__
    __delattr__ = dict.__delitem__


def warn_missing_config(key: str) -> None:
    print('Please fill the value of %s in mearc.config' % key)
    exit(-1)


def run_cmd_with_output(cmd: str) -> Dict[str, str]:
    process = subprocess.run(
        cmd.split(' '),
        shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE
    )
    process.wait()
    return {'stdout': process.stdout.decode(), 'stderr': process.stderr.decode()}


def run_cmd_without_output(cmd: str) -> None:
    process = subprocess.Popen(
        cmd,
        shell=True, stdout=subprocess.PIPE
    )
    process.wait()


def run_cmd_show_output(cmd: str) -> None:
    process = subprocess.Popen(
        cmd,
        shell=True
    )
    process.wait()


def __ccg2lambda(nlspec: str, configs, prog_name: str, identifier: str) -> Tuple[str, str, str]:
    info and print('INFO:using ccg2lambda to get MR from (%s)' % nlspec)
    debug and print('DEBUG: ccgslambda - tokenization')
    global nlp_path
    process = subprocess.Popen(
        ("echo \"%s\" | sed -f %s/en/tokenizer.sed > %s/sentences.tok" % (nlspec, nlp_path, configs.TMP)),
        shell=True, stdout=subprocess.PIPE
    )
    process.wait()
    debug and print('DEBUG: ccgslambda - C & C parsing')
    process = subprocess.Popen(
        ("%s/candc-1.00/bin/candc  --log %s/candc.log --models %s/candc-1.00/models --candc-printer xml --input "
         "%s/sentences.tok > %s/sentences.candc.xml" % (nlp_path, configs.TMP, nlp_path, configs.TMP, configs.TMP)),
        shell=True, stdout=subprocess.PIPE
    )
    process.wait()
    debug and print('DEBUG: ccgslambda - translate C & C parsing result to CCG rules')
    process = subprocess.Popen(
        ("%s %s/en/candc2transccg_wsc.py %s/sentences.candc.xml > %s/sentences.xml" % (
            configs.PYCMD, nlp_path, configs.TMP, configs.TMP)),
        shell=True, stdout=subprocess.PIPE
    )
    process.wait()
    debug and print('DEBUG: ccgslambda - mapping CCG rules with the templates')
    process = subprocess.run(
        ("%s %s/scripts/semparse_wsc.py %s/sentences.xml %s/en/semantic_templates_en_emnlp2015.yaml > "
         "%s/%s.conditions.mr.%s" % (
             configs.PYCMD, nlp_path, configs.TMP, nlp_path, configs.TMP, prog_name, identifier)),
        shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE
    )
    mr_file_path = ("%s/%s.conditions.mr.%s" % (configs.TMP, prog_name, identifier))
    mr_error = process.stderr.decode()
    mr_stdout = process.stdout.decode()
    return (mr_file_path, mr_error, mr_stdout)


def __depccg(nlspec: str, configs, prog_name: str, identifier: str) -> Tuple[str, str, str]:
    info and print('INFO:using depccg to get MR from (%s)' % nlspec)
    from pipeline_depccg import call_depccg_pipeline
    mr = call_depccg_pipeline(nlspec).strip()
    mr_error = None
    if not mr:
        mr_error = 'Failed'
    info and print('INFO: depccg executed')
    mr_file_path = ("%s/%s.conditions.mr.%s" % (configs.TMP, prog_name, identifier))
    while True:
        tuples = find_parens(mr)
        # if 0 not in tuples or tuples[0] != len(mr) - 1:
        #     break
        # else:
        #     mr = mr[1: -1]
        if 0 not in tuples:
            break
        else:
            mr = mr[:tuples[0]] + mr[tuples[0] + 1:]
            mr = mr[1:]
    with open(mr_file_path, 'w') as fp:
        fp.write(mr)
    return mr_file_path, mr_error, None


def find_parens(s):
    toret = {}
    pstack = []

    for i, c in enumerate(s):
        if c == '(':
            pstack.append(i)
        elif c == ')':
            if len(pstack) == 0:
                raise IndexError("No matching closing parens at: " + str(i))
            toret[pstack.pop()] = i

    if len(pstack) > 0:
        raise IndexError("No matching opening parens at: " + str(pstack.pop()))

    return toret


def __run_nlp_pipeline(nlspec: str, configs, prog_name: str, identifier: str):
    (mr_file_path, mr_error, mr_stdout) = globals()['__%s' % frontend](nlspec, configs, prog_name, identifier)

    if mr_error:
        print('Failed', file=sys.stderr)
        with open('%s/%s.error' % (configs.TMP, prog_name), 'a') as fp:
            fp.write(mr_error)
        return None
    else:
        info and print('INFO:MR generation done')

    with open(mr_file_path) as fp:
        mr = fp.read()
    if not mr or not mr.strip():
        print('MR generation failed for the following specification: ')
        print(nlspec)
        return None
    else:
        debug and print('DEBUG: going to translate the following mr: ')
        debug and print('DEBUG: ', mr)
        return mr_file_path, mr_error, mr_stdout


def __call_compiler(mr_file_path, si_file_path, _type: str):
    cmd = "./bin/main -f%s -s%s,%s" % (mr_file_path, si_file_path, si_path)
    print(cmd)
    process = subprocess.run(
        cmd.split(' '),
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE
    )
    # generated jml from translator
    cond = process.stdout.decode().strip()
    error = process.stderr.decode()
    if cond:
        keyword = None
        if _type == 'precondition':
            keyword = 'requires'
        elif _type == 'postcondition':
            keyword = 'ensures'
        elif _type == 'invariant':
            keyword = 'invariant'

        if keyword:
            print('%s(%s);' % (keyword, cond))
        else:
            print('Compiler output: %s ' % cond)
            print('Unknown condition type: %s.' % _type)
        return '%s(%s);' % (keyword, cond)
    else:
        print('Failed', file=sys.stderr)
        return None


# def write_to_jml_file(jmls: List[Tuple[str | None, str | None]], file_path: str, prog_name: str):
#     for i, jml in enumerate(jmls):
#         with open('%s/%s.conditions.query.%d' % (file_path, prog_name, i), 'w+') as fp:
#             for item in jml:
#                 if item[0] != 'ALSO':
#                     fp.write("//@ %s\n" % item[0])
#                     fp.write("//@ %s\n" % item[1])
#                 else:
#                     fp.write("//@ %s\n" % item[1])


def main(config_path: str, prog_file_path: str, query_path: str = None, prof_query_path: str = None) -> None:
    with open(config_path) as fp:
        _config = yaml.load(fp, Loader=SafeLoader)
    for key in _configs:
        if not _config[key] or (not isinstance(_config[key], list) and not _config[key].strip()):
            warn_missing_config(key)
        else:
            _configs[key] = _config[key]
    configs = dot_access_dict(_configs)
    global nlp_path, si_path
    nlp_path = [nlp.get(frontend.upper()) for nlp in configs.NLP][1]
    si_path = [si.get(frontend.upper()) for si in configs.STD_SI][1]
    prog_name = prog_file_path.replace('.java', '').split('/')[-1]
    si_file_path = ("%s/%s.si.yml" % (configs.TMP, prog_name))

    # create tmp folder
    run_cmd_without_output('mkdir -p %s; rm -rf %s/*' % (configs.TMP, configs.TMP))
    # preprocessing
    #############################################################
    # 20230623 added in Macau
    # adding query file support
    #############################################################
    if query_path and prof_query_path:
        cmd = "%s ./src/python/preprocessor.py -f %s -s %s -o %s -q %s -p %s" % (
        configs.PYCMD, prog_file_path, si_path, configs.TMP, query_path, prof_query_path)
    elif query_path:
        cmd = "%s ./src/python/preprocessor.py -f %s -s %s -o %s -q %s" % (
        configs.PYCMD, prog_file_path, si_path, configs.TMP, query_path)
    else:
        cmd = "%s ./src/python/preprocessor.py -f %s -s %s -o %s" % (configs.PYCMD, prog_file_path, si_path, configs.TMP)
    print(cmd)
    run_cmd_show_output(cmd)
    prog_condition_file = "%s/%s.conditions.yml" % (configs.TMP, prog_name)
    prog_si_file = "%s/%s.si.yml" % (configs.TMP, prog_name)
    if not os.path.exists(prog_condition_file) or not os.path.exists(prog_si_file):
        print('Preprocessing failed.')
        exit(-2)
    else:
        info and print('INFO:Preprocessing done')
    with open("%s/%s.conditions.yml" % (configs.TMP, prog_name)) as fp:
        data = yaml.load(fp, Loader=SafeLoader)
    # TODO changing the handling method when there is a query file
    if query_path:
        jmls = []
        count = 0
        failed_mr_files = []
        for i, specs in enumerate(data):
            ######################################################################
            # 20230626 added in Macau
            # for those spec pairs come with precondition and postcondition
            ######################################################################            
            jml = []
            for j, spec in enumerate(specs):
                precondition = spec['precondition']
                postcondition = spec['postcondition']
                tmp = __run_nlp_pipeline(precondition, configs, prog_name, 'query_%d_pair_%d_pre' % (i, j))
                _pre = None
                _post = None
                mr_file_path = None
                if tmp:
                    (mr_file_path, mr_error, mr_stdout) = tmp
                    _pre = __call_compiler(mr_file_path, si_file_path, 'precondition')
                else:
                    print("Precondition MR generation failed in query %d pair %d" % (i, j))
                if not _pre:
                    print("Compilation failed in query %d pair %d, please check with the MR in following path: \n%s" % (
                    i, j, mr_file_path))
                    count += 1
                    failed_mr_files.append('query_%d_pair_%d_pre' % (i, j))
                tmp = __run_nlp_pipeline(postcondition, configs, prog_name, 'query_%d_pair_%d_post' % (i, j))
                if tmp:
                    (mr_file_path, mr_error, mr_stdout) = tmp
                    _post = __call_compiler(mr_file_path, si_file_path, 'postcondition')
                else:
                    print("Postcondition MR generation failed in query %d pair %d" % (i, j))
                if not _post:
                    print("Compilation failed in query %d pair %d, please check with the MR in following path: \n%s" % (
                    i, j, mr_file_path))
                    count += 1
                    failed_mr_files.append('query_%d_pair_%d_post' % (i, j))
                if _pre and _post:
                    jml.append((_pre, _post))
                    jml.append(("ALSO", 'also'))
            jml = jml[:-1]
            jmls.append(jml)
        # write_to_jml_file(jmls=jmls, file_path=configs.TMP, prog_name=prog_name)
        print('Number of MRs that cannot be compiled: ', count)
        if count:
            print('Please refer to the following MR files: ')
            [print(f) for f in failed_mr_files]
        print('Generating JML files...')
        from esc import write_JML_files
        write_JML_files(jmls, prog_file_path=prog_file_path, prog_name=prog_name, target_path=configs.TMP)
    else:
        for i, record in enumerate(data):
            t = record['type']
            nlspec = record['specification']
            tmp = __run_nlp_pipeline(nlspec, configs, prog_name, str(i))
            if tmp:
                (mr_file_path, mr_error, mr_stdout) = tmp
                print(__call_compiler(mr_file_path, si_file_path, t))


if __name__ == "__main__":
    (options, args) = optparser.parse_args()
    if options.prog_path == None:
        print("Please provide the program file path")
    elif options.config_path == None:
        print("Please provide the config file path")
    else:
        if options.debuglevel == 1:
            info = True
        elif options.debuglevel == 2:
            info = True
            debug = True
        else:
            info = False
            debug = False

        if options.frontend == None or options.frontend not in frontends:
            info and print("Using default frontend(ccg2lambda)")
        else:
            frontend = options.frontend
        if not options.query:
            main(options.config_path, options.prog_path)
        else:
            if not options.prof_query:
                main(options.config_path, options.prog_path, query_path=options.query)
            else:
                main(options.config_path, options.prog_path, query_path=options.query,
                     prof_query_path=options.prof_query)
